# -*- coding: utf-8 -*-
# """naive-bayse-ml.ipynb

# Automatically generated by Colaboratory.

# Original file is located at
#     https://colab.research.google.com/drive/18TD2hJd0gEUQNsfwFrE30TvuE4cHBJN0
# # """

from sklearn.naive_bayes import GaussianNB
from sklearn.preprocessing import RobustScaler
import category_encoders as ce
from sklearn.impute import SimpleImputer
from sklearn.model_selection import StratifiedShuffleSplit
import urllib
from zipfile import ZipFile
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import joblib
warnings.filterwarnings("ignore")


# # """# Retrieve Data"""
DOWNLOAD_ROOT = 'https://raw.githubusercontent.com/sayid-alt/naive-bayes-classification/main'
CUSTOMER_PATH = os.path.join('datasets', 'adult')
CUSTOMER_URL = DOWNLOAD_ROOT + '/datasets/adult/adult.zip'


def fetch_adult_data(customer_path=CUSTOMER_PATH, customer_url=CUSTOMER_URL):
    os.makedirs(customer_path, exist_ok=True)
    zip_file = os.path.join(customer_path, 'adult.zip')
    urllib.request.urlretrieve(customer_url, zip_file)
    with ZipFile(zip_file, 'r') as zObject:
        zObject.extractall(path=customer_path)


fetch_adult_data()

# # """# Load Customers Data"""


def load_adult_data(csv_path=CUSTOMER_PATH):
    csv_file = os.path.join(csv_path, 'adult.csv')
    return pd.read_csv(csv_file, header=None, skipinitialspace=True)


customers = load_adult_data()

col_names = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship',
             'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income']

customers.columns = col_names

# column categories
cat_columns = [x for x in customers.columns if customers[x].dtype == 'O']
customers_cat = customers[cat_columns]


# """There is a missing value that coded with ? instead of NaN. However python just only can detect the missing value that coded with NaN.

# # ## Exploration in Workclass Variable
# """
customers['workclass'].replace('?', np.NaN, inplace=True)

# """## Exploration in occupation variables"""
customers['occupation'].replace('?', np.NaN, inplace=True)


# """## Exploration in native_country variable"""
customers['native_country'].replace('?', np.NaN, inplace=True)

# """## Explore numerical variables"""

num_columns = [x for x in customers.columns if customers[x].dtype != 'O']

customers_num = customers[num_columns]

# """# Split test train"""

sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)

for train_index, test_index in sss.split(customers, customers['income']):
    strat_train_set = customers.loc[train_index]
    strat_test_set = customers.loc[test_index]

strat_train_set.shape, strat_test_set.shape

strat_train_set.head()

# """# Declare custoemer features and labels"""

X_train = strat_train_set.drop('income', axis=1)
X_test = strat_test_set.drop('income', axis=1)
y_train = strat_train_set['income']
y_test = strat_test_set['income']


# """# Features engineering

# # Feature Engineering is the process of transforming raw data into useful features that help us to understand our model better and increase its predictive power. I will carry out feature engineering on different types of variables.
# """

# categorical variable
cat_columns = [cols for cols in X_train.columns if X_train[cols].dtypes == 'O']

# numerical variables
num_columns = [cols for cols in X_train.columns if X_train[cols].dtypes != 'O']

# Replace missing value with most frequent values
# using SimpleImputer scikit-learn library
imp_mode = SimpleImputer(strategy='most_frequent')
imp_mode.fit(X_train)

X_train = pd.DataFrame(imp_mode.transform(X_train), columns=X_test.columns)
X_test = pd.DataFrame(imp_mode.transform(X_test), columns=X_train.columns)


# # """## Encode Categorical Variable"""

encoder = ce.OneHotEncoder(cols=cat_columns)

X_train = encoder.fit_transform(X_train)
X_test = encoder.transform(X_test)


# # """# Feature Scaling"""
cols = X_train.columns

scaler = RobustScaler()

X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=cols)
X_test = pd.DataFrame(scaler.transform(X_test), columns=cols)


# # """# Model Training"""
gnb = GaussianNB()
gnb.fit(X_train, y_train)

# # """# Predict the result"""
y_pred = gnb.predict(X_test)

# store the predicted probabilities for class 1 - Probability of >50K
y_pred_prob_1 = gnb.predict_proba(X_test)[:, 1]


joblib.dump(gnb, "gnb_model.pkl")
gnb_model = joblib.load("gnb_model.pkl")
